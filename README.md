# Medical report generation
The Detectability Paradox: Bilingual Medical Report Generation with Open-Weight Models and the Limits of Human Oversight

## Introduction
This project investigates the quality and safety risks of using large language models (LLMs) to automate medical report generation in English and French. We evaluate medical reports generated by several multilingual LLMs using automated metrics and a medical expert panel, demonstrating high-quality output while highlighting the need for automated tools to detect machine-generated content.

## ğŸ¯ Overview
This repository contains the complete pipeline for:

1. **Data preprocessing** - Process raw medical data
2. **EHR simulation** - Generate synthetic electronic health records
3. **Report generation** - Generate medical reports (zero-shot & few-shot)
4. **Evaluation** - Automated metrics (ROUGE-1, BERTScore) and expert annotation
   
**Languages**: English & French  

## ğŸ“ Project structure
```bash

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # mtsamples urls, PubMed French PMIDs
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dev/                     # Development set (for few-shot prompting)
â”‚       â””â”€â”€ test/                    # Test set (for evaluation)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/               # Data preprocessing scripts
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_generation/
â”‚   â”‚   â”œâ”€â”€ ehr_simulation/          # EHR simulation
â”‚   â”‚   â”‚   â”œâ”€â”€ ehr_simulation.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py
â”‚   â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ report_generation/       # Medical report generation
â”‚   â”‚       â”œâ”€â”€ generate.py
â”‚   â”‚       â”œâ”€â”€ config.py
â”‚   â”‚       â”œâ”€â”€ prompts.py
â”‚   â”‚       â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # Automatic evaluation
â”‚   â”‚   â”œâ”€â”€ bertscore_evaluator.py
â”‚   â”‚   â””â”€â”€ rouge_evaluator.py      
â”‚   â”‚
â”‚   â””â”€â”€ expert_annotation/           # Expert evaluation setup
â”‚       â””â”€â”€ randomize_data.py        # Randomize samples for expert panel
â”‚
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ requirements.txt                 # Python dependencies
```

## ğŸš€ Installation

### Prerequisites

- Python 3.11+
- CUDA-capable GPU (for vLLM)

### Setup
```bash
# Clone repository
git clone https://github.com/ds4dh/medical_report_generation
cd medical_report_generation

# Install dependencies
pip install -r requirements.txt
```

## Contact
For questions or inquiries, please contact us at _hossein.rouhizadeh@unige.ch_.

