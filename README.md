# Medical report generation
The Detectability Paradox: Bilingual Medical Report Generation with Open-Weight Models and the Limits of Human Oversight

## Introduction
This project investigates the quality and safety risks of using large language models (LLMs) to automate medical report generation in English and French. We evaluate medical reports generated by several multilingual LLMs using automated metrics and a medical expert panel, demonstrating high-quality output while highlighting the need for automated tools to detect machine-generated content.

## ğŸ¯ Overview
This repository contains the complete pipeline for:

1. **Data preprocessing** - Process raw medical data
2. **EHR simulation** - Generate synthetic electronic health records
3. **Report generation** - Generate medical reports (zero-shot & few-shot)
4. **Evaluation** - Automated metrics (ROUGE-1, BERTScore) and expert annotation
   
**Languages**: English & French  

## ğŸ“ Project structure
```bash

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # mtsamples urls, PubMed French PMIDs
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dev/                     # Development set (for few-shot prompting)
â”‚       â””â”€â”€ test/                    # Test set (for evaluation)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/               # Data preprocessing scripts
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_generation/
â”‚   â”‚   â”œâ”€â”€ ehr_simulation/          # EHR simulation
â”‚   â”‚   â”‚   â”œâ”€â”€ ehr_simulation.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py
â”‚   â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ report_generation/       # Medical report generation
â”‚   â”‚       â”œâ”€â”€ generate.py
â”‚   â”‚       â”œâ”€â”€ config.py
â”‚   â”‚       â”œâ”€â”€ prompts.py
â”‚   â”‚       â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # Automatic evaluation
â”‚   â”‚   â”œâ”€â”€ bertscore_evaluator.py
â”‚   â”‚   â””â”€â”€ rouge_evaluator.py      
â”‚   â”‚
â”‚   â””â”€â”€ expert_annotation/           # Expert evaluation setup
â”‚       â””â”€â”€ randomize_data.py        # Randomize samples for expert panel
â”‚
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ requirements.txt                 # Python dependencies
```

## ğŸš€ Installation

### Prerequisites

- Python 3.11+
- CUDA-capable GPU (for vLLM)

### Setup
```bash
# Clone repository
git clone https://github.com/ds4dh/medical_report_generation
cd medical_report_generation

# Install dependencies
pip install -r requirements.txt
```
## âš¡ Quick start

### 1. Preprocess data

#### Step 1: Extract medical transcripts

Scrape medical transcripts from MTSamples.com:
```bash
cd src/preprocessing

# Scrape medical transcripts from MTSamples
python medical_transcript_scraper.py \
    --input_dir ../../data/raw/mtsamples_urls.csv \
    --output_dir ../../data/raw/english_medical_transcripts.csv
```
#### Step 2: Extract English case reports from the PMC-Patients dataset
To run this script, you need to download the source dataset from: https://github.com/pmc-patients/pmc-patients

```bash
cd src/preprocessing

python preprocessing_pmc_patients.py
    --input_dir path to "PMC-Patients.json" file \
    --output_dir 'english_case_reports.csv'
```

### 2. Generate reports
```bash
cd src/llm_generation/report_generation

# Zeroshot English case reports
python generate.py \
    --task case_report \
    --approach zeroshot \
    --language english \
    --input_file ../../../data/processed/test/case_reports.csv

# Fewshot French transcripts
python generate.py \
    --task transcript \
    --approach fewshot \
    --language french \
    --num_shots 3 \
    --input_file ../../../data/processed/test/transcripts.csv \
    --dev_file ../../../data/processed/dev/transcripts.csv
```

## Contact
For questions or inquiries, please contact us at _hossein.rouhizadeh@unige.ch_.

