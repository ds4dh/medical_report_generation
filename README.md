# Medical report generation
The Detectability Paradox: Bilingual Medical Report Generation with Open-Weight Models and the Limits of Human Oversight

## Introduction
This project investigates the quality and safety risks of using large language models (LLMs) to automate medical report generation in English and French. We evaluate medical reports generated by several multilingual LLMs using automated metrics and a medical expert panel, demonstrating high-quality output while highlighting the need for automated tools to detect machine-generated content.

## ğŸ¯ Overview
This repository contains the complete pipeline for:

1. **Data preprocessing** - Process raw medical data
2. **EHR simulation** - Generate synthetic electronic health records
3. **Report generation** - Generate medical reports (zero-shot & few-shot)
4. **Evaluation** - Automated metrics (ROUGE-1, BERTScore) and expert annotation
5. **Authorship Classification** - Detect machine-generated vs human-written medical reports

**Languages**: English & French  

## ğŸ“ Project structure
```bash

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # mtsamples urls, PubMed French PMIDs
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dev/                     # Development set (for few-shot prompting)
â”‚       â””â”€â”€ test/                    # Test set (for evaluation)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/               # Data preprocessing scripts
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_generation/
â”‚   â”‚   â”œâ”€â”€ ehr_simulation/          # EHR simulation
â”‚   â”‚   â”‚   â”œâ”€â”€ generate_ehr.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py
â”‚   â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ report_generation/       # Medical report generation
â”‚   â”‚       â”œâ”€â”€ generate_report.py
â”‚   â”‚       â”œâ”€â”€ config.py
â”‚   â”‚       â”œâ”€â”€ prompts.py
â”‚   â”‚       â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # Automatic evaluation
â”‚   â”‚   â”œâ”€â”€ bertscore_evaluator.py
â”‚   â”‚   â””â”€â”€ rouge_evaluator.py      
â”‚   â”‚
â”‚   â””â”€â”€ expert_annotation/           # Expert evaluation setup
â”‚   â”‚    â””â”€â”€ randomize_data.py        # Randomize samples for expert panel
â”‚   â”‚
â”‚   â””â”€â”€ authorship_classifier/        # Machine vs Human text detection
â”‚       â”œâ”€â”€ training/
â”‚       â”‚   â”œâ”€â”€ train.py             # Main training script
â”‚       â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚       â”‚   â”œâ”€â”€ dataset.py           # PyTorch Dataset
â”‚       â”‚   â”œâ”€â”€ evaluation.py        # Evaluation metrics
â”‚       â”‚   â”œâ”€â”€ inference.py         # Inference and predictions
â”‚       â”‚   â”œâ”€â”€ trainer.py           # Training logic
â”‚       â”‚   â””â”€â”€ utils.py             # Utilities
â”‚       â”‚
â”‚       â””â”€â”€ ig_scores/               # Integrated Gradients analysis
â”‚           â””â”€â”€ compute_ig.py        # Attribution scores      
â”‚       
â”‚ 
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ requirements.txt                 # Python dependencies
```

## ğŸš€ Installation

### Prerequisites

- Python 3.11+
- CUDA-capable GPU (for vLLM)

### Setup
```bash
# Clone repository
git clone https://github.com/ds4dh/medical_report_generation
cd medical_report_generation

# Install dependencies
pip install -r requirements.txt
```
## âš¡ Quick start

### 1. Preprocess data

#### Step 1: Extract medical transcripts

Scrape medical transcripts from MTSamples.com:
```bash
cd src/preprocessing

# Scrape medical transcripts from MTSamples
python medical_transcript_scraper.py \
    --input_dir ../../data/raw/mtsamples_urls.csv \
    --output_dir ../../data/raw/english_medical_transcripts.csv
```
#### Step 2: Extract English case reports from the PMC-Patients dataset
To run this script, you need to download the source dataset from: https://github.com/pmc-patients/pmc-patients

```bash
cd src/preprocessing

python preprocessing_pmc_patients.py
    --input_dir path to "PMC-Patients.json" file \
    --output_dir 'english_case_reports.csv'
```

### 2. Simulate EHR
```bash
cd src/llm_generation/ehr_simulation

python generate_ehr.py \
    --task case_report \
    --language english \
    --input_file ../../../data/processed/test/case_reports.csv


python generate_ehr.py \
    --task transcript \
    --language french \
    --input_file ../../../data/processed/test/medical_transcripts_test.csv
```


### 3. Generate reports
```bash
cd src/llm_generation/report_generation

# Zeroshot English case reports
python generate.py \
    --task case_report \
    --approach zeroshot \
    --language english \
    --input_file ../../../data/processed/test/case_reports.csv

# Fewshot French transcripts
python generate.py \
    --task transcript \
    --approach fewshot \
    --language french \
    --num_shots 3 \
    --input_file ../../../data/processed/test/transcripts.csv \
    --dev_file ../../../data/processed/dev/transcripts.csv
```
cd src/authorship_classifier/training

### 5. Train authorship classifier

```bash
cd src/authorship_classifier/training

# Train with default settings
python train.py --data_folder /path/to/data

# Train with custom model
python train.py \
    --data_folder /path/to/data \
    --model_name bert-base-multilingual-cased \
    --num_epochs 5 \
    --batch_size 16
```

#### Required Files
Place these files in your data folder:
- `train.csv` - training data
- `dev.csv` - development/validation data
- `test.csv` - test data

#### CSV format
**Required columns**:
- `text`: text content to classify
- `label`: label (0 = machine, 1 = human)

```csv
text,label
"This is machine-generated text...",0
"This is human-written text...",1
```


## Contact
For questions or inquiries, please contact us at _hossein.rouhizadeh@unige.ch_.

